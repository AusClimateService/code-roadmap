Many ACS researchers working at CSIRO will be able to store data and code in projects starting with the prefix `xv`.
This wiki page contains initial/draft thoughts on how we might manage those spaces.
To start the conversation,
here's a representation of how things might be organised,
using mainly the existing content in `xv83` as an example:

```
xv83/
├── projects/
|   ├── ACS_governance/
|   ├── ACS_project_1/
|   ├── ACS_project_2/
|   |   ├── ACS_work_package_1/
|   |   ├── ACS_work_package_2/
|   |   ├── ACS_work_package_3/
|   |   ├── ACS_work_package_4/
|   |   └── ACS_work_package_5/
|   ├── ESCI
|   |   ├── code/
|   |   └── data/
├── users/
│   ├── bxn599/
│   ├── cm2704/
│   ├── dbi599/
│   ├── dr6273/
│   ├── ds0092/
│   ├── kd7073/
│   ├── mxt599/
│   └── tm4888/

xv84/
├── admin/
├── shared/
|   ├── publications/
│   ├── authoritative/
│   │   ├── CAFE/
│   │   │   ├── README
│   │   │   ├── CAFE60v1/
│   │   │   ├── CAFE-f5/
│   │   │   └── CAFE-f6/
│   ├── reference_datasets/
|   │   ├── replicas/
|   │   │   ├── CCI_fire/
|   │   │   │   ├── README
|   │   │   │   └── *.nc
|   │   ├── post-processed/
|   │   │   ├── AWAP/
|   │   │   │   ├── code/
|   │   │   │   └── data/
|   │   │   ├── HadISST/
|   │   │   │   ├── code/
|   │   │   │   └── data/
|   │   │   └── JRA55/
|   │   │   │   ├── code/
|   │   │   │   └── data/

xv85/
xv86/
etc
```
What is described above is essentially a pipeline that goes from 'working space' (`xv83`) to 'shared space' (`xv84`, i.e. soft published data) to 'managed collection/s' (`xv85`, `xv86` onwards, i.e. hard published).

Researchers can essentially do what they like in their own personal `users` directory on `xv83`
(i.e. `/g/data/xv83/users/you123`),
but when it comes to `xv84/shared` data there will need to be some
standards/guidelines to ensure usability, transparency and reproducibility. 

### Authoritative datasets

e.g. `/g/data/xv84/shared/authoritative`

##### Description 
An authoritative dataset is the original/source version of a dataset.
For instance, the raw output (or raw with a minimal amount of post-processing)
from a model run or observational platform.
Many authoritative datasets are stored at NCI.
They are typically published on the [NCI data catalogue](https://geonetwork.nci.org.au),
which requires the authors to provide a bunch of detail about the dataset
(data description, contact information, license, etc)
for the public catalogue entry.
Upon publication, the dataset is issued with a DOI.

##### Requirements
A README file that describes the dataset in detail.
If the dataset isn't published on the NCI data catalogue,
we could require that most of the information required for a catalogue entry
is included in the README?

### Replica datasets 

e.g. `/g/data/xv84/shared/reference_datasets/replicas`

##### Description 
Many analyses conducted for the ACS will involve authoritative datasets
that aren't already available on NCI (e.g. a global reanalysis).
If there isn't a natural home elsewhere on NCI,
it may be necessary to download a (partial or complete) replica
of such a dataset and store it in `xv84`.

##### Requirements
A README file explaining when, how and what was downloaded from the authoritative source,
with appropriate links to dataset documentation. 

### Processed data  

`/g/data/xv84/shared/refereence_datasets/post-processed`

##### Description
While it isn't always necessary to store and share processed data
(because if you make the code and raw/original data available the processed data can be recreated),
it many cases it can be useful.
Examples of shared processed data might be simple manipulations of authoritative datasets
to achieve a desired grid resolution, temporal frequency or file format,
through to more complex processing to calculate a statistical quantity or climate diagnostic.
While the simple manipulations are likely to only be of use to other researchers within the ACS,
the complex products might be made available to stakeholders and/or the public. 

##### Requirements
Each processed data directory should include a `data/` and `code/` sub directory.
The code directory should include everything needed to reproduce the data.
This means: 
1. **Code:** A copy of all the code written/used to produce the data files (e.g. python scripts, R files, etc)
2. **Environment:** Details of the software environment that the code was executed in
(e.g. a conda `environment.yml` or `requirements.txt` file listing the installed libraries)
3. **Data processing steps:** Details of how (e.g. in what order) the code was executed to produce each data file
(e.g. a Makefile or simple README)

Ideally the `code/` directory should be a git repository that is hosted in the
[ACS GitHub organisation](https://github.com/AusClimateService) or
on [NCI GitLab](https://git.nci.org.au) so there's a place that members
of `xv84` can submit issues and ask questions about the processed data.

As an example, AGCD data has been processed (see `/g/data/xv83/dbi599/agcd`) and the
`code` directory is a git repository hosted at:  
https://github.com/AusClimateService/agcd 
